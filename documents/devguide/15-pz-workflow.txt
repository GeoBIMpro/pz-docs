# Workflow Service

The pz-workflow service enables the construction and use of "event" notifications to enable simple "if-this-happens-then-do-that" workflows.

A user will follow these general steps:

. Register a new event type
. Register a trigger for that event type
. Send an event
. Poll for new alerts
. Go to 3.

## Running Locally
To find out how to run the pz-workflow service locally, please visit the README at https://github.com/venicegeo/pz-workflow/blob/readme-updates/README.md
## The EventType

The user (or some service) first defines an `EventType` which is the "schema" for the events that the user will be generating. The `EventType` object is POSTed to `/eventType` and contains contains a `name` (string) and a map describing the event type's parameters.

The request payload looks like this:

[source,json]
----
{
    "name": "testevent-1468847218",
    "mapping": {
        "filename": "string",
        "code":     "string",
        "severity": "integer"
    }
}
----
The `name` must be unique across all event types.

The available data types are `string`, `boolean`, `integer`, `double`, `date`, `float`, `byte`, `short`, and `long`. (By no coincidence, these are the basic types that Elasticsearch supports.)

The response payload looks like this:

[source,json]
----
{
    "statusCode": 201,
    "type": "eventtype",
    "data": {
        "eventTypeId": "98fc25e8-bd97-4444-a972-c06aa0f0edf1",
        "name": "testevent-1468847218",
        "mapping": {
            "code": "string",
            "filename": "string",
            "severity": "integer"
        },
        "createdBy": "xyzzy",
        "createdOn": "2016-07-18T13:06:58.983944263Z",
    }
}
----


## The Trigger

The user then defines a `Trigger` which defines what action is to be taken when a specific event occurs. The `Trigger` is POSTed to `/trigger` and contains two parts, the `Condition` and the `Job`. The `Condition` defines what type of event is to be watched for and what the specific parameters of that event should be, expressed using Elasticsearch DSL query syntax against the parameters in the event type. The `Job` defines what action is to be taken, expressed as using Gateway/Dispatcher-style syntax.

The request payload looks like this:

[source,json]
----
{
    "title": "High Severity",
    "enabled": true,
    "condition": {
        "eventTypeIds": ["98fc25e8-bd97-4444-a972-c06aa0f0edf1"],
        "query": {
            "query": {
                "bool": {
                    "must": [
                        { "match": {"severity": 5} },
                        { "match": {"code": "PHONE"} }
                    ]
                }
            }
        }
    },
    "job": {
        "jobType": {
            "type": "execute-service",
            "data": {
                "serviceId": "a2898bcb-2646-4ffd-9da7-2308cb7e77d7",
                "dataInputs": {
                    "test": {
                        "content": "{ \"log\": \"Received code $code with severity $severity\" }",
                        "type": "body",
                        "mimeType": "application/json"
                    }
                },
                "dataOutput": [ {
                    "mimeType":"image/tiff",
                    "type":"raster"
                } ]
            }
        }
    }
}
----

`enabled` is a boolean value indicating whether the trigger should be "active" or not.

The caller supplies both the `eventTypeIds` and the `serviceId`.

In this example, the job will be executed only when an event of our previously defined `testevent-1468847218` event type occurs with its `severity` and `code` fields set to `5` and `"PHONE"`, respectively.

It's important to note that the "job" field uses substitution by replacing all instances of `$field` (where `field` is the name of a JSON field in the EventType `mapping` (and thus subsequently in the Event's `data` field)) with the `field` in the event that sets off the Trigger. This substitution occurs in all of the fields in `job`, so it is important to be conscious of this.

The response payload looks like this:

[source,json]
----
{
    "statusCode": 201,
    "type": "trigger",
    "data": {
        "triggerId": "6c9ce128-55c5-4aa0-80b2-a45f7f2bd367",
        "title": "High Severity",
        "condition": {
            "eventTypeIds": [
                "98fc25e8-bd97-4444-a972-c06aa0f0edf1"
            ],
            "query": {
                "query": {
                    "bool": {
                        "must": [
                        {
                            "match": {
                                "severity": 5
                            }
                        },
                        {
                            "match": {
                                "code": "PHONE"
                            }
                        }
                        ]
                    }
                }
            }
        },
        "job": {
            "createdBy": "test",
            "jobType": {
                "data": {
                    "serviceId": "a2898bcb-2646-4ffd-9da7-2308cb7e77d7"
                },
                "type": "execute-service"
            }
        },
        "percolationId": "6c9ce128-55c5-4aa0-80b2-a45f7f2bd367",
        "createdBy": "",
        "createdOn": "2016-07-18T13:11:51.163279767Z",
        "enabled": true
    }
}
----


## The Event

The user may generate an `Event` of that `EventType` to indicate some interesting condition has occurred. The `Event` object is POSTed to `/event` and contains the ID of the `EventType`, the date the event occurred, and the parameters of the event.

The request payload looks like this:

[source,json]
----
{
    "eventTypeId": "98fc25e8-bd97-4444-a972-c06aa0f0edf1",
    "data": {
        "filename": "dataset-c",
        "severity": 5,
        "code": "PHONE"
    }
}
----

The response payload looks like this:

[source,json]
----
{
    "statusCode": 201,
    "type": "event",
    "data": {
        "createdBy": "",
        "createdOn": "2016-07-18T13:20:17.520047787Z",
        "data": {
            "code": "PHONE",
            "filename": "dataset-c",
            "severity": 5
        },
        "eventId": "a765ea52-dac6-41e3-924e-19543f6f1100",
        "eventTypeId": "98fc25e8-bd97-4444-a972-c06aa0f0edf1"
    }
}
----

In addition, an _Event_ can specify a `cronSchedule` field, which alters the mechanics of the _Event_ slightly. The `cronSchedule` field specifies a schedule at which to repeat the specified event. This schedule is created as a cron expression. Users who are unfamiliar with cron expressions should check the man pages for cron, either via `man cron`, `man crontab`, or by searching online for cron related resources. Some helpful resources might include http://www.cronmaker.com[cronmaker.com] and http://crontab.guru[crontab.guru]. However, it is critical to note that the cron specification being used in our implementation is spelled out in https://github.com/robfig/cron/blob/master/doc.go, with the crucial difference being that our cron flavor designates the first asterisk as the *seconds* field. This means:

* `"cronSchedule": "* * * * * *"` sends the event every second;
* `"cronSchedule": "30 * * * * *"` sends the event every minute at the 30 second mark;
* `"cronSchedule": "* 30 * * * *"` sends the event every hour at the 30 minute mark, etc.

For reference, the 6 stars in the cronSchedule stand for:

*seconds | minutes | hours | (day of month) | month | (day of week)*

In some cron implementations, the rightmost asterisks can be omitted from the notation; this is not the case with the particular flavor of cron we are using.

Additionally, the `cronSchedule` field can be spelled out using shorthand notation:

.Shorthands
|===
|Entry |Description |Equivalent To

|@yearly (or @annually)
|Run once a year, midnight, Jan. 1st
|0 0 0 1 1 *

|@monthly
|Run once a month, midnight, first of month
|0 0 0 1 * *

|@weekly
|Run once a week, midnight on Sunday
|0 0 0 * * 0

|@daily (or @midnight)
|Run once a day, midnight
|0 0 0 * * *

|@hourly
|Run once an hour, beginning of hour
|0 0 * * * *
|===

Lastly, cronSchedule can be specified using the `@every duration` notation, where duration is replaced by a Go-parsable `time.Duration`. Examples include:

* `"cronSchedule": "@every 1h30m10s"`: send event every 1 hour, 30 minutes, 10 seconds
* `"cronSchedule": "@every 30s"`: send event every 30 seconds
* `"cronSchedule": "@every 5m"`: send event every 5 minutes

It is crucial to understand that an *Event that is sent with a `cronSchedule` field does not trigger the system in the same way that a typical event does*. Rather, it sets up a recurring Event that will be sent according to the schedule specified. If you require both an Event to be sent now as well as on a particular schedule, it is wise to send both a non-repeating Event and a repeating Event.

In order to stop repeating events, DELETE the initial repeating event by eventId.

    DELETE /event/{{eventId}}


## The Alert

Whenever the condition of a `Trigger` is met, the system will create an `Alert` object. The user can GET a list of alerts from `/alert`. The `Alert` object contains the ids of the `Trigger` that was hit and the `Event` which caused it. It also contains the now ubiquitous system-generated ID, and the id of the `Job` that was triggered by the event (note that at the current time, this is sent as a JobRequest, which may or may not become an actual job if the request is malformed).

Users do not create Alerts, so we do not show a request payload example.

The response payload looks like this:

[source,json]
----
{
    "statusCode": 200,
    "type": "alert-list",
    "data": [{
        "alertId": "886af5eb-ad7e-4bc1-a4aa-4b7703d86a67",
        "triggerId": "9b2db9f6-7cc4-4bfc-a14f-0949c87d5df2",
        "eventId": "94043c8e-b154-4dbd-98ba-fff2847abe07",
        "jobId": "2f773e8a-79b4-4115-9164-01f2d170e6c6",
        "createdBy": "xyzzy",
        "createdOn": "2016-07-18T12:43:10.25478657Z"
    }],
    "pagination": {
        "count": 1,
        "page": 0,
        "perPage": 10,
        "sortBy": "alertId",
        "order": "asc"
    }
}
----

For `GET` requests, the `?triggerId=...` query parameter is supported to allow filtering the list.


## Elasticsearch and Percolation

Elasticsearch indexes are used to store the event types, the events, the triggers, and the alerts.

When a new trigger is added, it's condition is entered into the events index's percolation index. When a new event is added, that percolation index is checked to see if any of the stored trigger conditions match. For those triggers that do match, their jobs are executed.


## Command Line App

The service is started as a command line app:

    $ pz-workflow

## HTTP API

### `POST /eventType`

Sends an EventType to the workflow service.

The POST body is a JSON request object, as shown above.

The available data types are: `string`, `boolean`, `integer`, `double`, `date`, `float`, `byte`, `short`, and `long`.

The return will be a 201 with the response payload shown above.


### `GET /eventType`

Returns 200 with a payload of an array of all the event types registered.

This endpoint supports pagination, as described in the <<Pagination>> section.


### `GET /eventType/:id`

Returns 200 with a payload of the event type with id of `:id`.


### `DELETE /eventType/:id`

Deletes the event type with id `:id`, and returns 200 with no payload.

_Delete should not be used unless you know what you are doing._


### `POST /event`

The POST body is a JSON request object as shown above.

The return will be a 201 with the response payload shown above.


### `GET /event`

Requests all the Events (of all EventTypes). Returns 200 with an array of `Event` objects.

This endpoint supports pagination, as described in the <<Pagination>> section.


### `GET /event/:id`

Requests a specific Event with id of `:id` and EventType `:eventtype`. Returns 200 with the `Event` object.


### `DELETE /event/:id`

Delete a specific Event and returns 200 with no payload.

_Delete should not be used unless you know what you are doing._


### `POST /alert`

Sends an Alert to the workflow service.

_POST support is for testing only; only the workflow service should generate alerts._


### `GET /alert`

Requests all the Alerts.

This endpoint supports pagination, as described in the <<Pagination>> section.

The query parameter `triggerId=id` filters the response set to only those Alerts with arising from the given Trigger.

The returned value is an array of `Alert` objects of the form shown above.


### `GET /alert/:id`

Requests a specific Alert with id of `:id`. Returns 200 and the `Alert` object.


### `DELETE /alert/:id`

Deletes the alert specified by the id value and returns 200 with no payload.

_Delete should not be used unless you know what you are doing._



### `POST /trigger`

Sends a Trigger to the workflow service with a request payload as shown above.


### `GET /trigger`

Requests all the Triggers. Returns 200 with an array of `Trigger` objects of the form shown above.

This endpoint supports pagination, as described in the <<Pagination>> section.


### `GET /trigger/:id`

Requests a Trigger with id of `:id`. Returns 200 with the `Trigger` object.


### `DELETE /trigger/:id`

Whacks the trigger specified by the `:id` value and returns 200.

_Delete should not be used unless you know what you are doing._


### Common operations

This service includes the common endpoints described in the <<Common Endpoints>> section.

The response object for a "stats" request looks like this:

[source,json]
----
{
    "createdOn": "2006-01-02T15:04:05+07:00",
    "numAlerts": 123,
    "numConditions": 234,
    "numEvents": 345,
    "numTriggers": 456
}
----

// vim: set syntax=asciidoc wrap:
