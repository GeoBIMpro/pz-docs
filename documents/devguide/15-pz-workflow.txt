# Workflow Service

## Overview
The pz-workflow service enables the construction and use of "event" notifications to enable simple "if-this-happens-then-do-that" workflows. This is done though an HTTP API. For a walkthough visit the Users Guide, for a simple overview visit `https://pz-swagger.geointservices.io/#/Workflow`.

A user will follow these general steps:

. Register a new event type
. Register a trigger for that event type
. Send an event
. Poll for new alerts
. Go to 3.

## Running Locally
To find out how to run the pz-workflow service locally, please visit the github [README](https://github.com/venicegeo/pz-workflow/blob/readme-updates/README.md)

## Technical

### Elasticsearch Interaction
[Elasticsearch][es-docs] is the chosen database for the workflow service. Elasticsearch can be defined as a 'nosql' using Lucene query. This can provide powerful query ability but at the cost of some inconveniences interacting with the database. When running locally workflow will automatically attach to a local elasticsearch instance, but when using an offsite elasticsearch addition information must be provided in the VCAP services.
Workflow has been designed in a way to reduce elasticsearch's 'nosql' capabilites. This is done by creating strict mapping types on all schemas. This insures that elasticsearch will only accept documents that exactly match the specified schema.
Workflow uses two packages in order to communicate with elasticsearch. The first of these is [pz-gocommon index file][go-com-i]. This allows workflow to create simple communication with an index. This index file itself relies on [elastic.v3][elastic3] to create the HTTP traffic.

### Kafka Interaction
Information on Kafka can be found [here][kafka-docs].
In workflow, Kafka service information must be provided in the VCAP services.
After an event 'triggers' a trigger, a job is sent to kafka. The function for this can be found [here][kafka-function].
Often when running workflow locally VCAP services are not provided, therefore no connection with kafka can be made, making jobs fail to be sent. A way of testing whether or not triggers work is checking to see if a kafka error was created in the workflow process terminal.

### Other Required Services

### Programmatic Hierarchy

[es-docs]: https://www.elastic.co/guide/en/elasticsearch/reference/current/index.html
[go-com-i]: https://github.com/venicegeo/pz-gocommon/blob/master/elasticsearch/index.go
[elastic3]: http://gopkg.in/olivere/elastic.v3
[kafka-docs]: https://kafka.apache.org/intro
[kafka-function]: https://github.com/venicegeo/pz-workflow/blob/ff8b869893f910145d5205ed2557f22ca0e1da24/workflow/Service.go#L206
// vim: set syntax=asciidoc wrap:
